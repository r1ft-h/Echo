```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• 
```

# SHAI Â â€”Â  Selfâ€‘Hosted AI Stack

**SHAI** delivers a productionâ€‘ready, GPUâ€‘accelerated inference stack combining:

* **vLLM** (OpenAIâ€‘compatible API)
* **OpenWebUI** (chat frontâ€‘end)
* A curated library of scripts to manage local models, updates and logging

Designed for consulting firms specialising in **Identity & Access Management (IAM)** but adaptable to any domain.

---

## âœ¨ Key Goals

1. **Data privacy**Â â€” run inference fully onâ€‘prem.
2. **Cost control**Â â€” oneâ€‘off hardware purchase beats SaaS token billing.
3. **Modularity**Â â€” WSLÂ 2, bareâ€‘metal, or Kubernetes; same workflow.
4. **Zeroâ€‘toâ€‘Chat** in â‰¤â€¯15â€¯min with automated installers.

---

## Repo Layout

```
SHAI/
â”œâ”€ bin/                   # Shell helpers (addâ€‘model, switchâ€‘model, etc.)
â”œâ”€ compose/               # Docker Compose files per target
â”‚  â”œâ”€ docker-compose.yml  # WSL flavour
â”‚  â””â”€ docker-compose-baremetal.yml
â”œâ”€ deploy/
â”‚  â”œâ”€ ubuntu_server/      # Bareâ€‘metal bootstrap
â”‚  â”œâ”€ wsl/                # WSLÂ 2 bootstrap
â”‚  â””â”€ k8s/                # Helm/Kustomize manifests (WIP)
â”œâ”€ doc/
â”‚  â”œâ”€ quickstart-baremetal.md
â”‚  â”œâ”€ shai-operations-handbook.md
â”‚  â””â”€ openwebui-admin-guide.md
â””â”€ models/                # (gitâ€‘ignored) local model cache
```

> **Tip:** Model payloads live outside Git in `/opt/shai/models/` once deployed.

---

## ğŸ“š Documentation Map

| Document                            | Description                                                      |
| ----------------------------------- | ---------------------------------------------------------------- |
| **doc/quickstart-baremetal.md**     | Endâ€‘toâ€‘end install on Ubuntu Server with NVIDIA GPU.             |
| **doc/shai-operations-handbook.md** | Hardware sizing, lifecycle management, advanced troubleshooting. |
| **doc/openwebui-admin-guide.md**    | Branding, authentication, feature flags for the frontâ€‘end.       |

For WSLÂ 2 or Kubernetes, see the respective README inside each `deploy/` subâ€‘folder.

---

## ğŸš€ Getting Started (Bareâ€‘Metal TL;DR)

```bash
# 1. Clone
sudo git clone https://github.com/<your-org>/SHAI.git /opt/shai-src

# 2. Bootstrap system
cd /opt/shai-src/deploy/ubuntu_server && sudo ./setup.sh
# Reboot if prompted, then reâ€‘login

# 3. Load a model
/opt/shai/bin/add-model.sh mistral7b-awq \
  TheBloke/Mistral-7B-Instruct-v0.2-AWQ --quant awq
/opt/shai/bin/switch-model.sh mistral7b-awq

# 4. Chat away
open http://<server-ip>:8080
```

---

## ğŸ¤ Contributing

PRs and issue reports are welcome. Please review `CONTRIBUTING.md` and open an issue before significant changes.

---

Â©Â 2025Â SH.AI â€” MITÂ License (see `LICENSE`)
