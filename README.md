# SHAIÂ Lab â€” **Selfâ€‘Hosted AIÂ Inference Stack**

> **One repoÂ â†’ every target**: WSLÂ 2 on Windows, bareâ€‘metal UbuntuÂ Server, and future k8s rigs.
>
> Productionâ€‘grade from dayâ€‘1 â€¢ GPUâ€‘powered vLLM backend â€¢ OpenWebUI front â€¢ Auditâ€‘ready admin toolkit.

---

## ğŸš€Â Why this project?

Running a local LLM is easyâ€¦ until you need:

* **Repeatable installs** across laptops, lab boxes *and* datacentre nodes.
* **Clean separation** between runtime (containersÂ + scripts) and bootstrap (OSâ€‘specific glue).
* **Audit & safety**: every admin action is logged; nothing is done as *root* once the stack is live.
* **Ready for tomorrow**: same tree works whether you scale to multiâ€‘GPU or migrate to Kubernetes.

SHAIÂ Lab is that opinionated skeleton. Clone â†’ run `setup.sh` â†’ `make up` â€” youâ€™re serving an OpenAIâ€‘compatible endpoint in minutes.

---

## ğŸ—ºï¸Â Repo layout (TL;DR)

```text
shai-lab/
â”œâ”€ bin/               # dayâ€‘toâ€‘day admin scripts (addâ€‘model, switchâ€‘model, â€¦)
â”œâ”€ compose/           # dockerâ€‘compose stack  (ports via .env)
â”œâ”€ deploy/            # oneâ€‘shot installers per target OS
â”‚   â”œâ”€ wsl/setup.sh   # WSLÂ 2 (UbuntuÂ 22.04)
â”‚   â””â”€ ubuntu/setup.sh# Bareâ€‘metal UbuntuÂ ServerÂ 22.04
â”œâ”€ docs/              # operator handbook, architecture notes
â”œâ”€ inventory/         # (optional) Ansible / Terraform hosts files
â”œâ”€ models/            # <empty> local HF weights (gitâ€‘ignored)
â”œâ”€ openwebui/data/    # OpenWebUI user DB (gitâ€‘ignored)
â”œâ”€ Makefile           # crossâ€‘platform helper commands
â””â”€ compose/.env.example  # copy to /opt/shai/.env after install
```

> \*\*Headsâ€‘upÂ \*\*: `models/`, `openwebui/data/`, `logs/`, and the real `.env` are excluded by `.gitignore`.

---

## ğŸÂ QuickÂ start

### WindowsÂ 10/11 â€¢Â WSLÂ 2

```powershell
#Â PowerShell
wsl --install -d Ubuntu-22.04   # if not yet enabled
wsl --shutdown                  # ensure systemd flag is read later
```

```bash
# inside WSL (UbuntuÂ 22.04 LTS)
git clone https://github.com/your-org/shai-lab.git
cd shai-lab/deploy/wsl
sudo ./setup.sh          # installs DockerÂ + NVIDIA toolkit + /opt/shai tree
exit                      # logout so group docker is applied
```

```powershell
wsl                       # relaunch WSL shell
```

```bash
cd ~/shai-lab             # repo root
cp compose/.env.example compose/.env
make up                   # pull images + start stack
```

Open [http://localhost:8080](http://localhost:8080) â†’ youâ€™re chatting with your GPU.

### Bareâ€‘metal UbuntuÂ ServerÂ 22.04

```bash
ssh user@server
sudo apt update && sudo apt install git -y
git clone https://github.com/your-org/shai-lab.git
cd shai-lab/deploy/ubuntu
sudo ./setup.sh
logout && login again     # docker group refresh
cd ~/shai-lab && cp compose/.env.example compose/.env && make up
```

---

## ğŸ› ï¸Â Daily operations

| Task             | Command                                                                             |
| ---------------- | ----------------------------------------------------------------------------------- |
| Download a model | `bin/add-model.sh mistral7b-awq mistralai/Mistralâ€‘7Bâ€‘Instructâ€‘v0.2â€‘AWQ --quant awq` |
| Activate model   | `bin/switch-model.sh mistral7b-awq`                                                 |
| See logs         | `tail -f /opt/shai/logs/bin-actions.log`                                            |
| Stop stack       | `make down`                                                                         |
| Update images    | `make update-all`                                                                   |

Full script referenceÂ â–¶ï¸Â `docs/Shai Lab Scripts Handbook.md`.

---

## ğŸ”Â Security highlights

* **No root** after initial install â€” scripts run under your user in the `docker` group.
* **All actions audited** to `/opt/shai/logs/bin-actions.log` (weekly rotation Ã—4).
* **OpenWebUI auth toggle** planned (`bin/enable-auth.sh`).

---

## ğŸ§±Â Roadâ€‘map

* [x] WSLÂ 2 + Ubuntu install scripts
* [x] Model download/switch helpers
* [ ] Service status & update helpers (`status.sh`, `update-all.sh`)
* [ ] Prometheus / Grafana exporter bundle
* [ ] K8s manifests (HelmÂ chart) in `deploy/k8s/`

> Have a feature in mind? PRs welcome â€” see **CONTRIBUTING.md** soon.

---

## ğŸ’¬Â Support & community

* IssuesÂ / feature requests â†’ GitHub **Issues** tab.
* Security concerns â†’ security\@yourâ€‘org.example.

---

## ğŸ“œÂ License

MIT â€” do whatever you want, just keep the copyright.